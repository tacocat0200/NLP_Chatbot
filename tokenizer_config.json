{
    "tokenizer_class": "BertTokenizer",
    "do_lower_case": true,
    "unk_token": "[UNK]",
    "sep_token": "[SEP]",
    "pad_token": "[PAD]",
    "cls_token": "[CLS]",
    "mask_token": "[MASK]",
    "model_max_length": 512
  }

{
    "tokenizer_class": "GPT2Tokenizer",
    "bos_token": "",
    "eos_token": "",
    "unk_token": "",
    "pad_token": "",
    "model_max_length": 1024
}

